{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "import csv\n",
    "import os\n",
    "\n",
    "RESULTS_DIR = '/Users/jarridr/repos/decagon/finals-new'\n",
    "INIT_DATA_SET_PROPORTION = 0.2\n",
    "\n",
    "DATA_SET_ID_IDX   = 0\n",
    "EPOCH_IDX         = 1\n",
    "LOSS_IDX          = 2\n",
    "LATENCY_IDX       = 3\n",
    "EVALUATED_ALL_IDX = 4\n",
    "EDGE_TYPE_IDX     = 5\n",
    "AUROC_IDX         = 7\n",
    "AUPRC_IDX         = 8\n",
    "APK_IDX           = 9\n",
    "\n",
    "class TrainingJobResults:\n",
    "    def __init__(\n",
    "        self, \n",
    "        activeLearningPolicy, \n",
    "        edgeTypePredicted, \n",
    "        dataSetProportion, \n",
    "        aurocVals, \n",
    "        auprcVals\n",
    "    ):\n",
    "        self.activeLearningPolicy = activeLearningPolicy \n",
    "        self.edgeTypePredicted = edgeTypePredicted\n",
    "        self.dataSetProportion = dataSetProportion\n",
    "        self.aurocVals = aurocVals\n",
    "        self.auprcVals = auprcVals\n",
    "        \n",
    "    def combine(self, other):\n",
    "        self.aurocVals.extend(other.aurocVals)\n",
    "        self.auprcVals.extend(other.auprcVals)\n",
    "        \n",
    "class DataSetInformation:\n",
    "    OkayPolicies = set(['RandomMasking', 'Greedy'])\n",
    "    OkayEdgeTypes = set(['Neutropenia', 'Hyperglycaemia', 'Anosmia'])\n",
    "    \n",
    "    def __init__(\n",
    "        self,\n",
    "        activeLearningPolicy, \n",
    "        edgeTypePredicted,\n",
    "        dataSetProportion, \n",
    "    ):  \n",
    "        if activeLearningPolicy not in DataSetInformation.OkayPolicies:\n",
    "            raise ValueError\n",
    "            \n",
    "        if edgeTypePredicted not in DataSetInformation.OkayEdgeTypes:\n",
    "            raise ValueError\n",
    "        \n",
    "        self.activeLearningPolicy = activeLearningPolicy \n",
    "        self.edgeTypePredicted = edgeTypePredicted\n",
    "        self.dataSetProportion = dataSetProportion\n",
    "        \n",
    "    def __hash__(self):\n",
    "        return hash((\n",
    "            self.activeLearningPolicy,\n",
    "            self.edgeTypePredicted,\n",
    "            self.dataSetProportion\n",
    "        ))\n",
    "\n",
    "def parseAll():    \n",
    "    result = {}\n",
    "    \n",
    "    for trainingJobResultsDict in map(parseFile, os.listdir(RESULTS_DIR)):\n",
    "        for trainingJobResults in trainingJobResultsDict.values():\n",
    "            activeLearnPol = trainingJobResults.activeLearningPolicy\n",
    "            if activeLearnPol not in result:\n",
    "                result[activeLearnPol] = {}\n",
    "\n",
    "            edgeTypePredicted = trainingJobResults.edgeTypePredicted\n",
    "            if edgeTypePredicted not in result[activeLearnPol]:\n",
    "                result[activeLearnPol][edgeTypePredicted] = {}\n",
    "\n",
    "            dataSetProportion = trainingJobResults.dataSetProportion\n",
    "            if dataSetProportion not in result[activeLearnPol][edgeTypePredicted]:\n",
    "                result[activeLearnPol][edgeTypePredicted][dataSetProportion] = trainingJobResults\n",
    "            else:\n",
    "                result[activeLearnPol][edgeTypePredicted][dataSetProportion].combine(trainingJobResults)\n",
    "\n",
    "    return result\n",
    "        \n",
    "\n",
    "def parseFile(rawFilename: str) -> TrainingJobResults:\n",
    "    result = {}\n",
    "    f = open('%s/%s' % (RESULTS_DIR, rawFilename))\n",
    "    reader = csv.reader(f)\n",
    "\n",
    "    # Skip the header\n",
    "    try:\n",
    "        next(reader)\n",
    "    except:\n",
    "        import pdb; pdb.set_trace()\n",
    "\n",
    "    for iteration in reader:\n",
    "        # Only use data for the first epoch\n",
    "        if iteration[EPOCH_IDX] != '1':\n",
    "            continue\n",
    "        \n",
    "        try:\n",
    "            dataSetInformation = parseDataSetId(iteration[DATA_SET_ID_IDX])\n",
    "        \n",
    "            if dataSetInformation not in result:\n",
    "                result[dataSetInformation] = TrainingJobResults(\n",
    "                    dataSetInformation.activeLearningPolicy,\n",
    "                    dataSetInformation.edgeTypePredicted,\n",
    "                    dataSetInformation.dataSetProportion,\n",
    "                    aurocVals=[],\n",
    "                    auprcVals=[]\n",
    "                )\n",
    "                \n",
    "            if float(iteration[AUROC_IDX]) < 0 or float(iteration[AUROC_IDX]) >= 1:\n",
    "                import pdb; pdb.set_trace()\n",
    "\n",
    "            if float(iteration[AUPRC_IDX]) < 0 or float(iteration[AUPRC_IDX]) >= 1:\n",
    "                import pdb; pdb.set_trace()\n",
    "\n",
    "            result[dataSetInformation].aurocVals.append(float(iteration[AUROC_IDX]))\n",
    "            result[dataSetInformation].auprcVals.append(float(iteration[AUPRC_IDX]))\n",
    "            \n",
    "        except:\n",
    "            continue\n",
    "    \n",
    "    f.close()\n",
    "    \n",
    "    return result\n",
    "        \n",
    "def parseDataSetId(dataSetId: str) -> DataSetInformation:\n",
    "    activeLearningPolicyStartIdx = 0\n",
    "    activeLearningPolicyEndIdx = dataSetId.find('ActiveLearner')\n",
    "    \n",
    "    edgeTypeStartIdx = dataSetId.find('DataSet') + len('DataSet')\n",
    "    edgeTypeEndIdx = dataSetId.find('AdjMtx')\n",
    "    \n",
    "    activeLearningPolicyIterNum = int(dataSetId[-1])\n",
    "    dataSetProportion = (20 + min(80, 2 ** activeLearningPolicyIterNum)) / 100\n",
    "    \n",
    "    return DataSetInformation(\n",
    "        dataSetId[activeLearningPolicyStartIdx:activeLearningPolicyEndIdx],\n",
    "        dataSetId[edgeTypeStartIdx:edgeTypeEndIdx],\n",
    "        dataSetProportion\n",
    "    )\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot the data!\n",
    "from typing import Dict, Iterable\n",
    "import seaborn as sns\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "TrainDataResults = Dict[str, Dict[str, Dict[float, TrainingJobResults]]]\n",
    "\n",
    "def getResultsDict(\n",
    "    policyName: str,\n",
    "    proportionToRes: Dict[float, TrainingJobResults], \n",
    "    plotAuprc\n",
    ") -> Dict[str, Iterable]:\n",
    "    def metricExtractor(results: Iterable[TrainingJobResults], plotAuprc: bool):\n",
    "        preAttrName = 'auprcVals' if plotAuprc else 'aurocVals' \n",
    "        metrics = list(map(lambda x: np.mean(getattr(x, preAttrName)), results))\n",
    "        \n",
    "        # Slice at -4 to exclude the \"Vals\" substring from attrName\n",
    "        return preAttrName[:-4], metrics\n",
    "\n",
    "    attrName, metrics = metricExtractor(proportionToRes.values(), plotAuprc)\n",
    "    \n",
    "    return {\n",
    "        'LearningPolicy': [policyName for _ in proportionToRes],\n",
    "        'DataSetProportion': [dataSetProportion for dataSetProportion in proportionToRes.keys()],\n",
    "        attrName: metrics\n",
    "    }\n",
    "\n",
    "def trainResultsAsDF(\n",
    "    trainResults: TrainDataResults, \n",
    "    edgeType: str, \n",
    "    plotAuprc: bool\n",
    ") -> pd.DataFrame:\n",
    "    randomResultsDict = getResultsDict(\n",
    "        'RandomMasking', \n",
    "        trainResults['RandomMasking'][edgeType], \n",
    "        plotAuprc\n",
    "    )\n",
    "    \n",
    "    greedyResultsDict = getResultsDict(\n",
    "        'Greedy', \n",
    "        trainResults['Greedy'][edgeType], \n",
    "        plotAuprc\n",
    "    )\n",
    "    \n",
    "    randResultsDf   = pd.DataFrame(randomResultsDict)\n",
    "    greedyResultsDf = pd.DataFrame(greedyResultsDict)\n",
    "    \n",
    "    return pd.concat([randResultsDf, greedyResultsDf])\n",
    "\n",
    "def plotData(trainResults: TrainDataResults, edgeType: str, plotAuprc: bool) -> None:\n",
    "    dataFrame = trainResultsAsDF(trainResults, edgeType, plotAuprc)\n",
    "    print(dataFrame.sort_values(['LearningPolicy', 'DataSetProportion']))\n",
    "    \n",
    "    #yKey = 'auprc' if plotAuprc else 'auroc'\n",
    "    #sns.lineplot(\n",
    "   #     x='DataSetProportion',\n",
    "    #    y=yKey,\n",
    "     #   hue='variable',\n",
    "      #  data=pd.melt(dataFrame, ['LearningPolicy']),\n",
    "       # estimator=None,\n",
    "        #style='choice'\n",
    "    #)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "allData: TrainDataResults = parseAll()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  LearningPolicy  DataSetProportion     auprc\n",
      "2         Greedy               0.21  0.524115\n",
      "3         Greedy               0.22  0.522429\n",
      "0         Greedy               0.24  0.498671\n",
      "1         Greedy               0.28  0.502927\n",
      "4         Greedy               0.36  0.504180\n",
      "7         Greedy               0.52  0.525956\n",
      "5         Greedy               0.84  0.489854\n",
      "6         Greedy               1.00  0.510412\n",
      "1  RandomMasking               0.21  0.485395\n",
      "5  RandomMasking               0.22  0.480674\n",
      "3  RandomMasking               0.24  0.512411\n",
      "6  RandomMasking               0.28  0.479880\n",
      "7  RandomMasking               0.36  0.525609\n",
      "0  RandomMasking               0.52  0.506830\n",
      "2  RandomMasking               0.84  0.527471\n",
      "4  RandomMasking               1.00  0.556734\n"
     ]
    }
   ],
   "source": [
    "plotData(allData, 'Hyperglycaemia', plotAuprc=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  LearningPolicy  DataSetProportion      auroc\n",
      "3         Greedy               0.21   0.487506\n",
      "2         Greedy               0.22   0.447600\n",
      "0         Greedy               0.24   0.471239\n",
      "1         Greedy               0.28   0.497573\n",
      "4         Greedy               0.36   0.513097\n",
      "7         Greedy               0.52   0.463504\n",
      "5         Greedy               0.84   0.452798\n",
      "6         Greedy               1.00   0.527050\n",
      "5  RandomMasking               0.21  10.538297\n",
      "3  RandomMasking               0.22   0.523455\n",
      "6  RandomMasking               0.24   0.506028\n",
      "7  RandomMasking               0.28   1.286772\n",
      "2  RandomMasking               0.36   0.518148\n",
      "0  RandomMasking               0.52   0.473112\n",
      "1  RandomMasking               0.84   0.581148\n",
      "4  RandomMasking               1.00   0.458353\n"
     ]
    }
   ],
   "source": [
    "plotData(allData, 'Anosmia', plotAuprc=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'RandomMasking': {'Anosmia': {0.52: <__main__.TrainingJobResults at 0x7fb7f10e6dd0>,\n",
       "   0.84: <__main__.TrainingJobResults at 0x7fb800c28210>,\n",
       "   0.36: <__main__.TrainingJobResults at 0x7fb830e61610>,\n",
       "   0.22: <__main__.TrainingJobResults at 0x7fb7f0e05dd0>,\n",
       "   1.0: <__main__.TrainingJobResults at 0x7fb7d935cbd0>,\n",
       "   0.21: <__main__.TrainingJobResults at 0x7fb830e32110>,\n",
       "   0.24: <__main__.TrainingJobResults at 0x7fb7f0b4f210>,\n",
       "   0.28: <__main__.TrainingJobResults at 0x7fb7d0947910>},\n",
       "  'Neutropenia': {0.28: <__main__.TrainingJobResults at 0x7fb7d0e8f690>,\n",
       "   0.36: <__main__.TrainingJobResults at 0x7fb7d1462910>,\n",
       "   0.24: <__main__.TrainingJobResults at 0x7fb7f1727a10>,\n",
       "   0.22: <__main__.TrainingJobResults at 0x7fb7d935ca50>,\n",
       "   0.21: <__main__.TrainingJobResults at 0x7fb7d93b2dd0>},\n",
       "  'Hyperglycaemia': {0.52: <__main__.TrainingJobResults at 0x7fb7d0dfd790>,\n",
       "   0.21: <__main__.TrainingJobResults at 0x7fb7d0bb0250>,\n",
       "   0.84: <__main__.TrainingJobResults at 0x7fb830e37390>,\n",
       "   0.24: <__main__.TrainingJobResults at 0x7fb830fbb310>,\n",
       "   1.0: <__main__.TrainingJobResults at 0x7fb830f464d0>,\n",
       "   0.22: <__main__.TrainingJobResults at 0x7fb7d0b26a50>,\n",
       "   0.28: <__main__.TrainingJobResults at 0x7fb7d9f08a90>,\n",
       "   0.36: <__main__.TrainingJobResults at 0x7fb7d0d49a90>}},\n",
       " 'Greedy': {'Anosmia': {0.24: <__main__.TrainingJobResults at 0x7fb7d0e8f3d0>,\n",
       "   0.28: <__main__.TrainingJobResults at 0x7fb800c3b4d0>,\n",
       "   0.22: <__main__.TrainingJobResults at 0x7fb7f1003b50>,\n",
       "   0.21: <__main__.TrainingJobResults at 0x7fb7d9217290>,\n",
       "   0.36: <__main__.TrainingJobResults at 0x7fb7d0b75d10>,\n",
       "   0.84: <__main__.TrainingJobResults at 0x7fb7d8f804d0>,\n",
       "   1.0: <__main__.TrainingJobResults at 0x7fb7d9923d50>,\n",
       "   0.52: <__main__.TrainingJobResults at 0x7fb7d0d49e10>},\n",
       "  'Hyperglycaemia': {0.24: <__main__.TrainingJobResults at 0x7fb7d1463890>,\n",
       "   0.28: <__main__.TrainingJobResults at 0x7fb831598490>,\n",
       "   0.21: <__main__.TrainingJobResults at 0x7fb7f18c7590>,\n",
       "   0.22: <__main__.TrainingJobResults at 0x7fb810b34d10>,\n",
       "   0.36: <__main__.TrainingJobResults at 0x7fb7f0d22c90>,\n",
       "   0.84: <__main__.TrainingJobResults at 0x7fb7f0c46a90>,\n",
       "   1.0: <__main__.TrainingJobResults at 0x7fb7d0c4c6d0>,\n",
       "   0.52: <__main__.TrainingJobResults at 0x7fb7d9c9c8d0>}}}"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "parseAll()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
